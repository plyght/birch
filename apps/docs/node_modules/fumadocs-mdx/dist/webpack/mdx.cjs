"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __esm = (fn, res) => function __init() {
  return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/loaders/mdx/preset.ts
var preset_exports = {};
__export(preset_exports, {
  getDefaultMDXOptions: () => getDefaultMDXOptions
});
function pluginOption(def, options = []) {
  const list = def(Array.isArray(options) ? options : []).filter(
    Boolean
  );
  if (typeof options === "function") {
    return options(list);
  }
  return list;
}
function getDefaultMDXOptions({
  valueToExport = [],
  rehypeCodeOptions,
  remarkImageOptions,
  remarkHeadingOptions,
  remarkStructureOptions,
  remarkCodeTabOptions,
  remarkNpmOptions,
  _withoutBundler = false,
  ...mdxOptions
}) {
  const remarkPlugins = pluginOption(
    (v) => [
      plugins.remarkGfm,
      [
        plugins.remarkHeading,
        {
          generateToc: false,
          ...remarkHeadingOptions
        }
      ],
      remarkImageOptions !== false && [
        plugins.remarkImage,
        {
          ...remarkImageOptions,
          useImport: _withoutBundler ? false : remarkImageOptions?.useImport
        }
      ],
      "remarkCodeTab" in plugins && remarkCodeTabOptions !== false && [
        plugins.remarkCodeTab,
        remarkCodeTabOptions
      ],
      "remarkNpm" in plugins && remarkNpmOptions !== false && [plugins.remarkNpm, remarkNpmOptions],
      ...v,
      remarkStructureOptions !== false && [
        plugins.remarkStructure,
        remarkStructureOptions
      ],
      () => {
        return (_, file) => {
          file.data["mdx-export"] ??= [];
          for (const name of valueToExport) {
            if (name in file.data)
              file.data["mdx-export"].push({ name, value: file.data[name] });
          }
        };
      }
    ],
    mdxOptions.remarkPlugins
  );
  const rehypePlugins = pluginOption(
    (v) => [
      rehypeCodeOptions !== false && [plugins.rehypeCode, rehypeCodeOptions],
      ...v,
      plugins.rehypeToc
    ],
    mdxOptions.rehypePlugins
  );
  return {
    ...mdxOptions,
    outputFormat: _withoutBundler ? "function-body" : mdxOptions.outputFormat,
    remarkPlugins,
    rehypePlugins
  };
}
var plugins;
var init_preset = __esm({
  "src/loaders/mdx/preset.ts"() {
    "use strict";
    plugins = __toESM(require("fumadocs-core/mdx-plugins"), 1);
  }
});

// src/config/build.ts
function buildCollection(name, config) {
  if (config.type === "docs") {
    return {
      ...config,
      name,
      meta: buildPrimitiveCollection(name, config.meta),
      docs: buildPrimitiveCollection(name, config.docs)
    };
  }
  return buildPrimitiveCollection(name, config);
}
function buildPrimitiveCollection(name, { files, ...config }) {
  const supportedFormats = SupportedFormats[config.type];
  const patterns = files ?? [`**/*.{${supportedFormats.join(",")}}`];
  let matchers;
  return {
    ...config,
    name,
    patterns,
    isFileSupported(filePath) {
      return supportedFormats.some((format) => filePath.endsWith(`.${format}`));
    },
    hasFile(filePath) {
      matchers ??= (Array.isArray(config.dir) ? config.dir : [config.dir]).map(
        (dir) => (0, import_picomatch.default)(patterns, {
          cwd: dir
        })
      );
      return this.isFileSupported(filePath) && matchers.some((matcher) => matcher(filePath));
    }
  };
}
function buildConfig(config) {
  const collections = /* @__PURE__ */ new Map();
  const loaded = {};
  for (const [k, v] of Object.entries(config)) {
    if (!v) {
      continue;
    }
    if (typeof v === "object" && "type" in v) {
      if (v.type === "docs") {
        collections.set(k, buildCollection(k, v));
        continue;
      }
      if (v.type === "doc" || v.type === "meta") {
        collections.set(
          k,
          buildCollection(k, v)
        );
        continue;
      }
    }
    if (k === "default" && v) {
      Object.assign(loaded, v);
      continue;
    }
    throw new Error(
      `Unknown export "${k}", you can only export collections from source configuration file.`
    );
  }
  if (loaded.collections) {
    for (const [k, v] of Object.entries(loaded.collections)) {
      collections.set(k, buildCollection(k, v));
    }
  }
  const mdxOptionsCache = /* @__PURE__ */ new Map();
  return {
    global: loaded,
    collectionList: Array.from(collections.values()),
    getCollection(name) {
      return collections.get(name);
    },
    async getDefaultMDXOptions(mode = "default") {
      const cached = mdxOptionsCache.get(mode);
      if (cached) return cached;
      const input = this.global.mdxOptions;
      async function uncached() {
        const options = typeof input === "function" ? await input() : input;
        const { getDefaultMDXOptions: getDefaultMDXOptions2 } = await Promise.resolve().then(() => (init_preset(), preset_exports));
        if (options?.preset === "minimal") return options;
        return getDefaultMDXOptions2({
          ...options,
          _withoutBundler: mode === "remote"
        });
      }
      const result = uncached();
      mdxOptionsCache.set(mode, result);
      return result;
    }
  };
}
var import_picomatch, SupportedFormats;
var init_build = __esm({
  "src/config/build.ts"() {
    "use strict";
    import_picomatch = __toESM(require("picomatch"), 1);
    SupportedFormats = {
      doc: ["mdx", "md"],
      meta: ["json", "yaml"]
    };
  }
});

// src/config/load-from-file.ts
var load_from_file_exports = {};
__export(load_from_file_exports, {
  loadConfig: () => loadConfig
});
async function compileConfig(configPath, outDir) {
  const { build } = await import("esbuild");
  const transformed = await build({
    entryPoints: [{ in: configPath, out: "source.config" }],
    bundle: true,
    outdir: outDir,
    target: "node20",
    write: true,
    platform: "node",
    format: "esm",
    packages: "external",
    outExtension: {
      ".js": ".mjs"
    },
    allowOverwrite: true
  });
  if (transformed.errors.length > 0) {
    throw new Error("failed to compile configuration file");
  }
}
async function loadConfig(configPath, outDir, build = false) {
  if (build) await compileConfig(configPath, outDir);
  const url = (0, import_node_url2.pathToFileURL)(path6.resolve(outDir, "source.config.mjs"));
  url.searchParams.set("hash", Date.now().toString());
  const config = import(url.href).then(
    (loaded) => buildConfig(loaded)
  );
  return await config;
}
var path6, import_node_url2;
var init_load_from_file = __esm({
  "src/config/load-from-file.ts"() {
    "use strict";
    path6 = __toESM(require("path"), 1);
    import_node_url2 = require("url");
    init_build();
  }
});

// src/webpack/mdx.ts
var mdx_exports = {};
__export(mdx_exports, {
  default: () => loader
});
module.exports = __toCommonJS(mdx_exports);

// src/utils/fuma-matter.ts
var import_js_yaml = require("js-yaml");
var regex = /^---\r?\n(.+?)\r?\n---\r?\n/s;
function fumaMatter(input) {
  const output = { matter: "", data: {}, content: input };
  const match = regex.exec(input);
  if (!match) {
    return output;
  }
  output.matter = match[0];
  output.content = input.slice(match[0].length);
  const loaded = (0, import_js_yaml.load)(match[1]);
  output.data = loaded ?? {};
  return output;
}

// src/utils/validation.ts
var import_picocolors = __toESM(require("picocolors"), 1);
var ValidationError = class extends Error {
  constructor(message, issues) {
    super(
      `${message}:
${issues.map((issue) => `  ${issue.path}: ${issue.message}`).join("\n")}`
    );
    this.title = message;
    this.issues = issues;
  }
  toStringFormatted() {
    return [
      import_picocolors.default.bold(`[MDX] ${this.title}:`),
      ...this.issues.map(
        (issue) => import_picocolors.default.redBright(
          `- ${import_picocolors.default.bold(issue.path?.join(".") ?? "*")}: ${issue.message}`
        )
      )
    ].join("\n");
  }
};
async function validate(schema, data, context, errorMessage) {
  if (typeof schema === "function" && !("~standard" in schema)) {
    schema = schema(context);
  }
  if ("~standard" in schema) {
    const result = await schema["~standard"].validate(
      data
    );
    if (result.issues) {
      throw new ValidationError(errorMessage, result.issues);
    }
    return result.value;
  }
  return data;
}

// src/utils/git-timestamp.ts
var import_node_path = __toESM(require("path"), 1);
var import_tinyexec = require("tinyexec");
var cache = /* @__PURE__ */ new Map();
async function getGitTimestamp(file) {
  const cached = cache.get(file);
  if (cached) return cached;
  try {
    const out = await (0, import_tinyexec.x)(
      "git",
      ["log", "-1", '--pretty="%ai"', import_node_path.default.relative(process.cwd(), file)],
      {
        throwOnError: true
      }
    );
    const time = new Date(out.stdout);
    cache.set(file, time);
    return time;
  } catch {
    return;
  }
}

// src/loaders/mdx/build-mdx.ts
var import_mdx = require("@mdx-js/mdx");

// src/loaders/mdx/remark-include.ts
var import_unified = require("unified");
var import_unist_util_visit2 = require("unist-util-visit");
var path2 = __toESM(require("path"), 1);
var fs = __toESM(require("fs/promises"), 1);
var import_mdx_plugins = require("fumadocs-core/mdx-plugins");

// src/loaders/mdx/remark-unravel.ts
var import_unist_util_visit = require("unist-util-visit");
function remarkMarkAndUnravel() {
  return (tree) => {
    (0, import_unist_util_visit.visit)(tree, function(node, index, parent) {
      let offset = -1;
      let all = true;
      let oneOrMore = false;
      if (parent && typeof index === "number" && node.type === "paragraph") {
        const children = node.children;
        while (++offset < children.length) {
          const child = children[offset];
          if (child.type === "mdxJsxTextElement" || child.type === "mdxTextExpression") {
            oneOrMore = true;
          } else if (child.type === "text" && child.value.trim().length === 0) {
          } else {
            all = false;
            break;
          }
        }
        if (all && oneOrMore) {
          offset = -1;
          const newChildren = [];
          while (++offset < children.length) {
            const child = children[offset];
            if (child.type === "mdxJsxTextElement") {
              child.type = "mdxJsxFlowElement";
            }
            if (child.type === "mdxTextExpression") {
              child.type = "mdxFlowExpression";
            }
            if (child.type === "text" && /^[\t\r\n ]+$/.test(String(child.value))) {
            } else {
              newChildren.push(child);
            }
          }
          parent.children.splice(index, 1, ...newChildren);
          return index;
        }
      }
    });
  };
}

// src/loaders/mdx/remark-include.ts
var ElementLikeTypes = [
  "mdxJsxFlowElement",
  "mdxJsxTextElement",
  "containerDirective",
  "textDirective",
  "leafDirective"
];
function isElementLike(node) {
  return ElementLikeTypes.includes(node.type);
}
function parseElementAttributes(element) {
  if (Array.isArray(element.attributes)) {
    const attributes = {};
    for (const attr of element.attributes) {
      if (attr.type === "mdxJsxAttribute" && (typeof attr.value === "string" || attr.value === null)) {
        attributes[attr.name] = attr.value;
      }
    }
    return attributes;
  }
  return element.attributes ?? {};
}
function flattenNode(node) {
  if ("children" in node)
    return node.children.map((child) => flattenNode(child)).join("");
  if ("value" in node) return node.value;
  return "";
}
function parseSpecifier(specifier) {
  const idx = specifier.lastIndexOf("#");
  if (idx === -1) return { file: specifier };
  return {
    file: specifier.slice(0, idx),
    section: specifier.slice(idx + 1)
  };
}
function extractSection(root, section) {
  let nodes;
  let capturingHeadingContent = false;
  (0, import_unist_util_visit2.visit)(root, (node) => {
    if (node.type === "heading") {
      if (capturingHeadingContent) {
        return false;
      }
      if (node.data?.hProperties?.id === section) {
        capturingHeadingContent = true;
        nodes = [node];
        return "skip";
      }
      return;
    }
    if (capturingHeadingContent) {
      nodes?.push(node);
      return "skip";
    }
    if (isElementLike(node) && node.name === "section") {
      const attributes = parseElementAttributes(node);
      if (attributes.id === section) {
        nodes = node.children;
        return false;
      }
    }
  });
  if (nodes)
    return {
      type: "root",
      children: nodes
    };
}
function remarkInclude() {
  const TagName = "include";
  const embedContent = async (file, heading, params, data) => {
    let content;
    try {
      content = (await fs.readFile(file)).toString();
    } catch (e) {
      throw new Error(
        `failed to read file ${file}
${e instanceof Error ? e.message : String(e)}`,
        { cause: e }
      );
    }
    const ext = path2.extname(file);
    data._compiler?.addDependency(file);
    if (params.lang || ext !== ".md" && ext !== ".mdx") {
      const lang = params.lang ?? ext.slice(1);
      return {
        type: "code",
        lang,
        meta: params.meta,
        value: content,
        data: {}
      };
    }
    const parser = data._getProcessor ? data._getProcessor(ext === ".mdx" ? "mdx" : "md") : this;
    const parsed = fumaMatter(content);
    let mdast = parser.parse({
      path: file,
      value: parsed.content,
      data: { frontmatter: parsed.data }
    });
    const baseProcessor = (0, import_unified.unified)().use(remarkMarkAndUnravel);
    if (heading) {
      const extracted = extractSection(
        await baseProcessor.use(import_mdx_plugins.remarkHeading).run(mdast),
        heading
      );
      if (!extracted)
        throw new Error(
          `Cannot find section ${heading} in ${file}, make sure you have encapsulated the section in a <section id="${heading}"> tag, or a :::section directive with remark-directive configured.`
        );
      mdast = extracted;
    } else {
      mdast = await baseProcessor.run(mdast);
    }
    await update(mdast, path2.dirname(file), data);
    return mdast;
  };
  async function update(tree, directory, data) {
    const queue = [];
    (0, import_unist_util_visit2.visit)(tree, ElementLikeTypes, (_node, _, parent) => {
      const node = _node;
      if (node.name !== TagName) return;
      const specifier = flattenNode(node);
      if (specifier.length === 0) return "skip";
      const attributes = parseElementAttributes(node);
      const { file: relativePath, section } = parseSpecifier(specifier);
      const file = path2.resolve(
        "cwd" in attributes ? process.cwd() : directory,
        relativePath
      );
      queue.push(
        embedContent(file, section, attributes, data).then((replace) => {
          Object.assign(
            parent && parent.type === "paragraph" ? parent : node,
            replace
          );
        })
      );
      return "skip";
    });
    await Promise.all(queue);
  }
  return async (tree, file) => {
    await update(tree, path2.dirname(file.path), file.data);
  };
}

// src/loaders/mdx/remark-postprocess.ts
var import_unist_util_visit3 = require("unist-util-visit");
var import_mdast_util_to_markdown = require("mdast-util-to-markdown");
var import_estree_util_value_to_estree = require("estree-util-value-to-estree");
var import_unist_util_remove_position = require("unist-util-remove-position");
var import_remark_mdx = __toESM(require("remark-mdx"), 1);
function remarkPostprocess({
  _format,
  includeProcessedMarkdown = false,
  includeMDAST = false,
  valueToExport = []
}) {
  let _stringifyProcessor;
  const getStringifyProcessor = () => {
    if (_format === "mdx") return this;
    return _stringifyProcessor ??= this().use(import_remark_mdx.default).freeze();
  };
  return (tree, file) => {
    let title;
    const urls = [];
    (0, import_unist_util_visit3.visit)(tree, ["heading", "link"], (node) => {
      if (node.type === "heading" && node.depth === 1) {
        title = flattenNode2(node);
      }
      if (node.type !== "link") return;
      urls.push({
        href: node.url
      });
      return "skip";
    });
    if (title) {
      file.data.frontmatter ??= {};
      if (!file.data.frontmatter.title) file.data.frontmatter.title = title;
    }
    file.data.extractedReferences = urls;
    if (includeProcessedMarkdown) {
      const processor = getStringifyProcessor();
      file.data._markdown = (0, import_mdast_util_to_markdown.toMarkdown)(tree, {
        ...processor.data("settings"),
        // from https://github.com/remarkjs/remark/blob/main/packages/remark-stringify/lib/index.js
        extensions: processor.data("toMarkdownExtensions") || []
      });
    }
    if (includeMDAST) {
      const options = includeMDAST === true ? {} : includeMDAST;
      file.data._mdast = JSON.stringify(
        options.removePosition ? (0, import_unist_util_remove_position.removePosition)(structuredClone(tree)) : tree
      );
    }
    for (const { name, value } of file.data["mdx-export"] ?? []) {
      tree.children.unshift(getMdastExport(name, value));
    }
    for (const name of valueToExport) {
      if (!(name in file.data)) continue;
      tree.children.unshift(getMdastExport(name, file.data[name]));
    }
  };
}
function getMdastExport(name, value) {
  return {
    type: "mdxjsEsm",
    value: "",
    data: {
      estree: {
        type: "Program",
        sourceType: "module",
        body: [
          {
            type: "ExportNamedDeclaration",
            attributes: [],
            specifiers: [],
            source: null,
            declaration: {
              type: "VariableDeclaration",
              kind: "let",
              declarations: [
                {
                  type: "VariableDeclarator",
                  id: {
                    type: "Identifier",
                    name
                  },
                  init: (0, import_estree_util_value_to_estree.valueToEstree)(value)
                }
              ]
            }
          }
        ]
      }
    }
  };
}
function flattenNode2(node) {
  if ("children" in node)
    return node.children.map((child) => flattenNode2(child)).join("");
  if ("value" in node) return node.value;
  return "";
}

// src/loaders/mdx/build-mdx.ts
var cache2 = /* @__PURE__ */ new Map();
async function buildMDX(cacheKey, source, options) {
  const { filePath, frontmatter, data, _compiler, ...rest } = options;
  function getProcessor(format) {
    const key = `${cacheKey}:${format}`;
    let processor = cache2.get(key);
    if (!processor) {
      processor = (0, import_mdx.createProcessor)({
        outputFormat: "program",
        ...rest,
        remarkPlugins: [
          remarkInclude,
          ...rest.remarkPlugins ?? [],
          [
            remarkPostprocess,
            {
              _format: format,
              ...options.postprocess,
              valueToExport: [
                ...options.postprocess?.valueToExport ?? [],
                "structuredData",
                "extractedReferences",
                "frontmatter",
                "lastModified",
                "_markdown",
                "_mdast"
              ]
            }
          ]
        ],
        format
      });
      cache2.set(key, processor);
    }
    return processor;
  }
  return getProcessor(
    options.format ?? (filePath.endsWith(".mdx") ? "mdx" : "md")
  ).process({
    value: source,
    path: filePath,
    data: {
      ...data,
      frontmatter,
      _compiler,
      _getProcessor: getProcessor
    }
  });
}

// src/loaders/mdx/index.ts
var import_zod = require("zod");
var import_promises = __toESM(require("fs/promises"), 1);
var import_node_path2 = __toESM(require("path"), 1);
var import_node_crypto = require("crypto");

// src/loaders/index.ts
var mdxLoaderGlob = /\.mdx?(\?.+?)?$/;

// src/loaders/mdx/index.ts
var querySchema = import_zod.z.object({
  only: import_zod.z.literal(["frontmatter", "all"]).default("all"),
  collection: import_zod.z.string().optional()
}).loose();
var cacheEntry = import_zod.z.object({
  code: import_zod.z.string(),
  map: import_zod.z.any().optional(),
  hash: import_zod.z.string().optional()
});
function createMdxLoader(configLoader) {
  return {
    test: mdxLoaderGlob,
    async load({
      getSource,
      development: isDevelopment,
      query,
      compiler,
      filePath
    }) {
      const value = await getSource();
      const matter = fumaMatter(value);
      const parsed = querySchema.parse(query);
      const config = await configLoader.getConfig();
      let after;
      if (!isDevelopment && config.global.experimentalBuildCache) {
        const cacheDir = config.global.experimentalBuildCache;
        const cacheKey = `${parsed.hash}_${parsed.collection ?? "global"}_${generateCacheHash(filePath)}`;
        const cached = await import_promises.default.readFile(import_node_path2.default.join(cacheDir, cacheKey)).then((content) => cacheEntry.parse(JSON.parse(content.toString()))).catch(() => null);
        if (cached && cached.hash === generateCacheHash(value)) return cached;
        after = async () => {
          await import_promises.default.mkdir(cacheDir, { recursive: true });
          await import_promises.default.writeFile(
            import_node_path2.default.join(cacheDir, cacheKey),
            JSON.stringify({
              ...out,
              hash: generateCacheHash(value)
            })
          );
        };
      }
      const collection = parsed.collection ? config.getCollection(parsed.collection) : void 0;
      let docCollection;
      switch (collection?.type) {
        case "doc":
          docCollection = collection;
          break;
        case "docs":
          docCollection = collection.docs;
          break;
      }
      if (docCollection?.schema) {
        matter.data = await validate(
          docCollection.schema,
          matter.data,
          {
            source: value,
            path: filePath
          },
          `invalid frontmatter in ${filePath}`
        );
      }
      if (parsed.only === "frontmatter") {
        return {
          code: `export const frontmatter = ${JSON.stringify(matter.data)}`,
          map: null
        };
      }
      const data = {};
      if (config.global.lastModifiedTime === "git") {
        data.lastModified = (await getGitTimestamp(filePath))?.getTime();
      }
      const lineOffset = isDevelopment ? countLines(matter.matter) : 0;
      const compiled = await buildMDX(
        `${getConfigHash(config)}:${parsed.collection ?? "global"}`,
        "\n".repeat(lineOffset) + matter.content,
        {
          development: isDevelopment,
          ...docCollection?.mdxOptions ?? await config.getDefaultMDXOptions(),
          postprocess: docCollection?.postprocess,
          data,
          filePath,
          frontmatter: matter.data,
          _compiler: compiler
        }
      );
      const out = {
        code: String(compiled.value),
        map: compiled.map
      };
      await after?.();
      return out;
    }
  };
}
var hashes = /* @__PURE__ */ new WeakMap();
function getConfigHash(config) {
  let hash = hashes.get(config);
  if (hash) return hash;
  hash = Date.now().toString();
  hashes.set(config, hash);
  return hash;
}
function generateCacheHash(input) {
  return (0, import_node_crypto.createHash)("md5").update(input).digest("hex");
}
function countLines(s) {
  let num = 0;
  for (const c of s) {
    if (c === "\n") num++;
  }
  return num;
}

// src/loaders/adapter.ts
var import_node_url = require("url");
var import_promises2 = __toESM(require("fs/promises"), 1);
var import_node_querystring = require("querystring");
var import_node_path3 = __toESM(require("path"), 1);
function toWebpack(loader2) {
  return async function(source, callback) {
    try {
      const result = await loader2.load({
        filePath: this.resourcePath,
        query: (0, import_node_querystring.parse)(this.resourceQuery.slice(1)),
        getSource() {
          return source;
        },
        development: this.mode === "development",
        compiler: this
      });
      if (result === null) {
        callback(void 0, source);
      } else {
        callback(void 0, result.code, result.map);
      }
    } catch (error) {
      if (error instanceof ValidationError) {
        return callback(new Error(error.toStringFormatted()));
      }
      if (!(error instanceof Error)) throw error;
      const fpath = import_node_path3.default.relative(this.context, this.resourcePath);
      error.message = `${fpath}:${error.name}: ${error.message}`;
      callback(error);
    }
  };
}

// src/core.ts
var import_node_path4 = __toESM(require("path"), 1);
var import_promises3 = __toESM(require("fs/promises"), 1);
function createCore(options, defaultPlugins = []) {
  let config;
  let plugins2;
  return {
    _options: options,
    getPluginContext() {
      return {
        core: this,
        ...options
      };
    },
    /**
     * Convenient cache store, reset when config changes
     */
    cache: /* @__PURE__ */ new Map(),
    async init({ config: newConfig }) {
      config = await newConfig;
      this.cache.clear();
      plugins2 = [];
      for await (const option of [
        ...defaultPlugins,
        ...config.global.plugins ?? []
      ]) {
        if (!option) continue;
        if (Array.isArray(option)) plugins2.push(...option);
        else plugins2.push(option);
      }
      for (const plugin of plugins2) {
        const out = await plugin.config?.call(this.getPluginContext(), config);
        if (out) config = out;
      }
      return this;
    },
    getConfig() {
      return config;
    },
    async initServer(server) {
      for (const plugin of plugins2) {
        await plugin.configureServer?.call(this.getPluginContext(), server);
      }
    },
    async emitAndWrite({
      filterPlugin = () => true
    } = {}) {
      const start = performance.now();
      const out = await Promise.all(
        plugins2.map((plugin) => {
          if (!filterPlugin(plugin) || !plugin.emit) return [];
          return plugin.emit.call(this.getPluginContext());
        })
      );
      await Promise.all(
        out.flat().map(async (entry) => {
          const file = import_node_path4.default.join(options.outDir, entry.path);
          await import_promises3.default.mkdir(import_node_path4.default.dirname(file), { recursive: true });
          await import_promises3.default.writeFile(file, entry.content);
        })
      );
      console.log(`[MDX] generated files in ${performance.now() - start}ms`);
    }
  };
}

// src/loaders/config.ts
var import_promises4 = __toESM(require("fs/promises"), 1);
function createStandaloneConfigLoader({
  core,
  buildConfig: buildConfig2,
  mode
}) {
  let loaded;
  async function getConfigHash2() {
    if (mode === "production") return "static";
    const stats = await import_promises4.default.stat(core._options.configPath).catch(() => {
      throw new Error("Cannot find config file");
    });
    return stats.mtime.getTime().toString();
  }
  async function newConfig() {
    const { loadConfig: loadConfig2 } = await Promise.resolve().then(() => (init_load_from_file(), load_from_file_exports));
    await core.init({
      config: loadConfig2(
        core._options.configPath,
        core._options.outDir,
        buildConfig2
      )
    });
    return core.getConfig();
  }
  return {
    async getConfig() {
      const hash = await getConfigHash2();
      if (loaded && loaded.hash === hash) return loaded.config;
      loaded = {
        hash,
        config: newConfig()
      };
      return loaded.config;
    }
  };
}

// src/webpack/mdx.ts
var instance;
async function loader(source, callback) {
  const { isDev, outDir, configPath } = this.getOptions();
  this.cacheable(true);
  this.addDependency(configPath);
  if (!instance) {
    const core = createCore({
      environment: "webpack",
      outDir,
      configPath
    });
    instance = toWebpack(
      createMdxLoader(
        createStandaloneConfigLoader({
          core,
          buildConfig: false,
          mode: isDev ? "dev" : "production"
        })
      )
    );
  }
  await instance.call(this, source, callback);
}
